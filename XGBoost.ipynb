{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698728e3-8b99-4191-b4c0-ea562a78182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack, vstack\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49bd991-46d0-47b4-adee-5387f7e1a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Matched Data (Positive)\n",
    "matches = pd.read_csv('data/HumanAnnotatedMatches_SVO_DB_20200127_pipes_noquotes.csv', encoding='UTF-8', on_bad_lines='skip', engine=\"python\", delimiter='|' )\n",
    "\n",
    "# Load Matched Data (Negative)\n",
    "non_matches = pd.read_csv('data/HumanAnnotatedMatches_poormatches_SVO_DB_20201027.csv', encoding='windows-1252')\n",
    "\n",
    "# Load All Data\n",
    "all_notams = pd.read_pickle(\"data/allData.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6fe113-1fc1-42c6-bfe6-f938faee8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive NOTAM IDs\n",
    "good_ids = matches['NOTAM_REC_ID']\n",
    "\n",
    "# Negative NOTAM IDs\n",
    "bad_ids = non_matches['NOTAM_REC_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a9611b-ce3c-4566-9c78-30b3ff4e11e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOTAM_REC_ID', 'FNS_ID', 'FILENAME', 'NOTAM_ID', 'NOTAM_TYPE',\n",
       "       'RELATED_NOTAM_ID', 'SIMPLE_TEXT', 'LOC_ID_ACCOUNTABLE_ORG',\n",
       "       'NOTAM_NUMBER', 'RELATED_NOTAM_NUMBER', 'TEXT', 'Q_CODE',\n",
       "       'Q_CODE_INTERPRETATION', 'A_CODE', 'B_CODE', 'C_CODE', 'D_CODE',\n",
       "       'E_CODE', 'F_CODE', 'G_CODE', 'CLASSIFICATION', 'POSSIBLE_NOTAM_ID',\n",
       "       'MIN_ALT', 'MAX_ALT', 'MIN_ALT_REF_TYPE', 'MAX_ALT_REF_TYPE',\n",
       "       'POSSIBLE_START_DATE', 'POSSIBLE_END_DATE', 'ISSUE_DATE',\n",
       "       'CANCELED_DATE', 'AFFECTED_FIR', 'DESIGNATOR', 'DESIGNATOR_NAME',\n",
       "       'LOCATION_NAME', 'ACCOUNT_ID', 'LOCATION_CODE', 'LAUNCHES_REC_ID',\n",
       "       'TOPIC', 'XGB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Cols\n",
    "all_notams.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e1f8d5-d1f1-4d1b-af36-8d3397c67c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Features\n",
    "features = ['NOTAM_TYPE', 'TEXT', 'CLASSIFICATION', 'MIN_ALT', 'MAX_ALT', 'LOCATION_CODE', 'TOPIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f232e42-b4c8-4136-b435-c7b5d7684733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Positive NOTAM Data\n",
    "good_notams = all_notams[all_notams['NOTAM_REC_ID'].isin(good_ids)][features]\n",
    "\n",
    "# Get Negaitve NOTAM Data\n",
    "bad_notams = all_notams[all_notams['NOTAM_REC_ID'].isin(bad_ids)][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610aa45b-1289-42b5-8d15-122cef5d2019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOTAM_TYPE', 'TEXT', 'CLASSIFICATION', 'MIN_ALT', 'MAX_ALT',\n",
       "       'LOCATION_CODE', 'TOPIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Cols\n",
    "bad_notams.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddf3a70-d08e-463a-b843-682f0e113923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Label Encoders\n",
    "le = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "\n",
    "# Type Encoder\n",
    "all_notams['NOTAM_TYPE'] = le.fit_transform(all_notams['NOTAM_TYPE'])\n",
    "good_notams['NOTAM_TYPE'] = le.transform(good_notams['NOTAM_TYPE'])\n",
    "bad_notams['NOTAM_TYPE'] = le.transform(bad_notams['NOTAM_TYPE'])\n",
    "\n",
    "# Classification Encoder\n",
    "all_notams['CLASSIFICATION'] = le2.fit_transform(all_notams['CLASSIFICATION'])\n",
    "good_notams['CLASSIFICATION'] = le2.transform(good_notams['CLASSIFICATION'])\n",
    "bad_notams['CLASSIFICATION'] = le2.transform(bad_notams['CLASSIFICATION'])\n",
    "\n",
    "# Location Code\n",
    "all_notams['LOCATION_CODE'] = le3.fit_transform(all_notams['LOCATION_CODE'])\n",
    "good_notams['LOCATION_CODE'] = le3.transform(good_notams['LOCATION_CODE'])\n",
    "bad_notams['LOCATION_CODE'] = le3.transform(bad_notams['LOCATION_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea1dbb7-7787-4cfb-bb64-3b9b4d445853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOTAM_TYPE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>MIN_ALT</th>\n",
       "      <th>MAX_ALT</th>\n",
       "      <th>LOCATION_CODE</th>\n",
       "      <th>TOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>airspace abel east military operations area ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>129.99</td>\n",
       "      <td>14277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>hnk vhf omnidirectional radio range intensity ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.00</td>\n",
       "      <td>12687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>microburst windshear detection system not avai...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.00</td>\n",
       "      <td>2376</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1</td>\n",
       "      <td>automatic dependent surveillance contract auto...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.00</td>\n",
       "      <td>5165</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1</td>\n",
       "      <td>surface movement radar shutdown for maintenance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.00</td>\n",
       "      <td>13606</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NOTAM_TYPE                                               TEXT  \\\n",
       "16             3  airspace abel east military operations area ac...   \n",
       "235            1  hnk vhf omnidirectional radio range intensity ...   \n",
       "640            1  microburst windshear detection system not avai...   \n",
       "719            1  automatic dependent surveillance contract auto...   \n",
       "1162           1    surface movement radar shutdown for maintenance   \n",
       "\n",
       "      CLASSIFICATION  MIN_ALT  MAX_ALT  LOCATION_CODE  TOPIC  \n",
       "16                 0     50.0   129.99          14277      0  \n",
       "235                2      0.0   999.00          12687      2  \n",
       "640                2      0.0   999.00           2376      4  \n",
       "719                2      0.0   999.00           5165      2  \n",
       "1162               2      0.0   999.00          13606      5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data\n",
    "bad_notams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6257cc21-8168-4a2b-90dd-ccdfe3dc45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Embedding\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', max_features=10000)\n",
    "\n",
    "# Fit and Transform All Data\n",
    "all_encodes = tfidf.fit_transform(all_notams['TEXT'])\n",
    "\n",
    "# Transform Positive Data\n",
    "good_encodes = tfidf.transform(good_notams['TEXT'])\n",
    "\n",
    "# Transform Negative Data\n",
    "bad_encodes = tfidf.transform(bad_notams['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e71d22-9bbf-4899-8791-23ce4fd9fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Classification Labels\n",
    "good_notams['LABEL'] = 1\n",
    "bad_notams['LABEL'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca193be-ef68-4f6f-bf92-b021e37accde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Features (Positive)\n",
    "positive = hstack((good_notams['NOTAM_TYPE'].array[:,None], \n",
    "                   good_encodes,\n",
    "                   good_notams['CLASSIFICATION'].array[:,None],\n",
    "                   good_notams['MIN_ALT'].array[:,None],\n",
    "                   good_notams['MAX_ALT'].array[:,None],\n",
    "                   good_notams['LOCATION_CODE'].array[:,None],\n",
    "                   good_notams['TOPIC'].array[:,None])).A\n",
    "\n",
    "# Combine Features (Negative)\n",
    "negative = hstack((bad_notams['NOTAM_TYPE'].array[:,None], \n",
    "                   bad_encodes,\n",
    "                   bad_notams['CLASSIFICATION'].array[:,None],\n",
    "                   bad_notams['MIN_ALT'].array[:,None],\n",
    "                   bad_notams['MAX_ALT'].array[:,None],\n",
    "                   bad_notams['LOCATION_CODE'].array[:,None],\n",
    "                   bad_notams['TOPIC'].array[:,None])).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930db9f4-68dc-49f4-8211-5a7ffe434d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitialize K-Fold SPlit for Cross Validation\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=232323)\n",
    "\n",
    "# Combine Postive and Negative Data\n",
    "X = vstack((positive, negative))\n",
    "y = vstack((good_notams['LABEL'].array[:,None], bad_notams['LABEL'].array[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3b72424-948c-46b7-a37e-6d5137691967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9130982367758187\n",
      "Accuracy: 0.906801007556675\n",
      "Accuracy: 0.9105793450881612\n",
      "Accuracy: 0.9042821158690176\n",
      "Accuracy: 0.9042821158690176\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "for train_index, test_index in sss.split(X.toarray(), y.toarray()):\n",
    "    X_train, X_test = X.tocsr()[train_index], X.tocsr()[test_index]\n",
    "    y_train, y_test = y.tocsr()[train_index].toarray(), y.tocsr()[test_index].toarray()\n",
    "\n",
    "    test_model = XGBClassifier()\n",
    "    test_model.fit(X_train, y_train)\n",
    "    yhat = test_model.predict(X_test)\n",
    "\n",
    "    print('Accuracy:', accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f04afbbd-466b-43ae-8b32-c49a7acd32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Features (All Data)\n",
    "pred = hstack((all_notams['NOTAM_TYPE'].array[:,None], \n",
    "                   all_encodes,\n",
    "                   all_notams['CLASSIFICATION'].array[:,None],\n",
    "                   all_notams['MIN_ALT'].array[:,None],\n",
    "                   all_notams['MAX_ALT'].array[:,None],\n",
    "                   all_notams['LOCATION_CODE'].array[:,None],\n",
    "                   all_notams['TOPIC'].array[:,None])).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40a0b69-4183-416b-9b8c-4c67ef29ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Training\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y.toarray())\n",
    "\n",
    "# Predict All NOTAMs\n",
    "all_notams['XGB'] = model.predict(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6203aa-96b5-4b69-bf37-401d606b9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Restults\n",
    "all_notams.to_pickle(\"data/allData.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
