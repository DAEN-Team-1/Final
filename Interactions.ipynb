{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bf70e1-9693-4091-8bcf-9c54591490af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "import shapely.wkt\n",
    "from shapely import geometry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71641098-05f5-42f4-a00b-c6e9a9c05436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates WKT Polygons\n",
    "def getPolygons(id_list):\n",
    "    all_polys = {}\n",
    "\n",
    "    for poly_id in id_list:\n",
    "        tmp = df2[df2['POLYGON_ID'] == poly_id]\n",
    "\n",
    "        long = tmp['LONGITUDE'].astype(str).values\n",
    "        lat = tmp['LATITUDE'].astype(str).values\n",
    "\n",
    "        pointList = list(zip(tmp['LONGITUDE'], tmp['LATITUDE']))\n",
    "\n",
    "        if len(pointList) == 1:\n",
    "            poly = geometry.Point([pointList[0][0], pointList[0][1]])\n",
    "        elif len(pointList) == 2:\n",
    "            poly = geometry.LineString([[p[0], p[1]] for p in pointList])\n",
    "        else:\n",
    "            poly = geometry.Polygon([[p[0], p[1]] for p in pointList])\n",
    "\n",
    "        all_polys[poly_id] = poly\n",
    "        \n",
    "    return all_polys\n",
    "\n",
    "# Gets Poylgon ID from NOTAM ID\n",
    "def getIds(rec_ids, poly_df):\n",
    "    id_list = []\n",
    "    for row in rec_ids['NOTAM_REC_ID']:\n",
    "        for item in poly_df[poly_df['NOTAM_REC_ID'] == row]['POLYGON_ID'].values:\n",
    "            id_list.append(item)\n",
    "            \n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab8c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a utility function for converting distance values using different units\n",
    "def conv_dist(distance_value, units_value):\n",
    "    # Determine the conversion factor for the specified units (meters are required for this projection)\n",
    "    if units_value == \"mi\":\n",
    "        unit_factor = 1609.344\n",
    "    elif units_value == \"km\":\n",
    "        unit_factor = 1000.0\n",
    "    elif units_value == \"ft\":\n",
    "        unit_factor = 0.3048\n",
    "    elif units_value == \"nm\":\n",
    "        unit_factor = 1852\n",
    "    elif units_value == \"m\":\n",
    "        unit_factor = 1\n",
    "    else:  # Bad units\n",
    "        unit_factor = 0\n",
    "\n",
    "    return distance_value * unit_factor\n",
    "\n",
    "#This function creates geospatial circle(s) based on center, radius and unit values in the dataset\n",
    "def gen_geocircle(input_df, key_col, center_col, radius_col, units_col):\n",
    "\n",
    "    # Convert point data to geopandas dataframe\n",
    "#    pointsdf = input_df[[key_col, center_col, radius_col, units_col]]\n",
    "\n",
    "    working_cols = [key_col] + [center_col] + [radius_col] + [units_col]\n",
    "    return_cols = [key_col] + [\"buffer\"]\n",
    "    \n",
    "    pointsdf = input_df[working_cols]\n",
    "    \n",
    "#    pointsdf[center_col] = gpd.GeoSeries.from_wkt(pointsdf[center_col])\n",
    "    gdf_pts = geopandas.GeoDataFrame(pointsdf, geometry=center_col)\n",
    "\n",
    "    # Add CRS (start with WGS84 to match lat/lon values)\n",
    "    gdf_pts.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    #Prepare projection (North America Lambert Conformal Conic)\n",
    "    # This projection is equidistant for measuring between points.\n",
    "    # Units are in meters\n",
    "    projout = '+proj=lcc +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs'\n",
    "\n",
    "    # Convert to Lambert projection\n",
    "    gdf_pts = gdf_pts.to_crs(projout)\n",
    "\n",
    "    # -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    gdf_pts[units_col] = gdf_pts[units_col].str.lower()\n",
    "    gdf_pts[\"dist\"] = 0\n",
    "\n",
    "    # -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    for pt_index,pt_row in gdf_pts.iterrows():\n",
    "        dvalue = conv_dist(pt_row[2], pt_row[3])\n",
    "\n",
    "        gdf_pts.loc[pt_index,'dist'] = dvalue\n",
    "\n",
    "#    gdf2 = pd.merge(gdf_pts[[\"locid\",\"ArptLocation\"]], params[[\"locid\",\"dist\"]], on='locid')\n",
    "\n",
    "    gdf_pts[\"buffer\"] = gdf_pts[center_col].buffer(gdf_pts['dist'])\n",
    "\n",
    "    # -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    gdf_circle = gdf_pts[return_cols]\n",
    "\n",
    "    gdf_circle = geopandas.GeoDataFrame(gdf_circle, geometry='buffer')\n",
    "\n",
    "    gdf_circle = gdf_circle.to_crs(epsg=4326)\n",
    "\n",
    "    \n",
    "    return gdf_circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3824ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function determines takes two sets of geospatial objects and determines which ones interact\n",
    "def find_interactions(geom_set1_df, geom_set2_df,\n",
    "                      set1_key_cols, set2_key_cols,\n",
    "                      set1_geometry_col, set2_geometry_col\n",
    "                      ):\n",
    "\n",
    "    set1_working_cols = set1_key_cols + [set1_geometry_col]\n",
    "    set2_working_cols = set2_key_cols + [set2_geometry_col]\n",
    "    \n",
    "    # Convert point data to geopandas dataframe\n",
    "\n",
    "    gdf1 = geom_set1_df[set1_working_cols]\n",
    "#    gdf1[set1_geometry_col] = gpd.GeoSeries.from_wkt(gdf1[set1_geometry_col])\n",
    "    gdf1 = geopandas.GeoDataFrame(gdf1, geometry=set1_geometry_col)\n",
    "\n",
    "    # Add CRS (start with WGS84 to match lat/lon values)\n",
    "    gdf1.set_crs(epsg=4326, inplace=True)\n",
    "    gdf1_type = gdf1.loc[0, set1_geometry_col].geom_type\n",
    "\n",
    "    #Convert polygon data to geopandas dataframe\n",
    "    gdf2 = geom_set2_df[set2_working_cols]\n",
    "#    gdf2[set2_geometry_col] = gpd.GeoSeries.from_wkt(gdf2[set2_geometry_col])\n",
    "    gdf2 = geopandas.GeoDataFrame(gdf2, geometry=set2_geometry_col)\n",
    "\n",
    "    # Add CRS (start with WGS84 to match lat/lon values)\n",
    "    gdf2.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    gdf2_type = gdf2.loc[0, set2_geometry_col].geom_type\n",
    "\n",
    "    #If datasets are mixed (one polygon and one linestring), ensure polygons are gdf1\n",
    "    if (gdf1_type == 'LineString' or gdf1_type == 'Point') and gdf2_type == 'Polygon':\n",
    "        gdf_temp = gdf1\n",
    "        gdf1 = gdf2\n",
    "        gdf2 = gdf_temp\n",
    "        gdf2_type = gdf1_type\n",
    "        gdf1_type = 'Polygon'\n",
    "        keys_temp = set1_key_cols\n",
    "        set1_key_cols = set2_key_cols\n",
    "        set2_key_cols = keys_temp\n",
    "        geom_temp = set1_geometry_col\n",
    "        set1_geometry_col = set2_geometry_col\n",
    "        set2_geometry_col = geom_temp\n",
    "        \n",
    "    # Convert to new equidistant projection\n",
    "\n",
    "    #Prepare projection (North America Lambert Conformal Conic)\n",
    "    # This projection is equidistant for measuring between points.\n",
    "    # Units are in meters\n",
    "    projout = '+proj=lcc +lat_1=20 +lat_2=60 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs'\n",
    "\n",
    "    # Convert to Lambert projection\n",
    "    gdf1 = gdf1.to_crs(projout)\n",
    "\n",
    "    # Convert to Lambert projection\n",
    "    gdf2 = gdf2.to_crs(projout)\n",
    "\n",
    "#    if gdf2_type == 'Point':\n",
    "#        results = pd.DataFrame(columns=(set1_key_cols + ['Within_polygon']))\n",
    "#    else:\n",
    "    results = pd.DataFrame(columns=(set1_key_cols + set2_key_cols + ['Interaction']))\n",
    "    \n",
    "    df_index = 0\n",
    "    \n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    for gdf1_index,gdf1_row in gdf1.iterrows():\n",
    "        for gdf2_index,gdf2_row in gdf2.iterrows():\n",
    "            if gdf1_type == 'Polygon' and gdf2_type == 'LineString':\n",
    "                interaction = gdf1.loc[gdf1_index, set1_geometry_col].intersects(gdf2.loc[gdf2_index, set2_geometry_col])\n",
    "                if interaction:\n",
    "                    start_pt, end_pt = gdf2.loc[gdf2_index, set2_geometry_col].boundary\n",
    "                    if gdf1.loc[gdf1_index, set1_geometry_col].contains(gdf2.loc[gdf2_index, set2_geometry_col]):\n",
    "                        interact_str = ['Contains']\n",
    "                    elif gdf1.loc[gdf1_index, set1_geometry_col].contains(start_pt):\n",
    "                        interact_str = ['Start']\n",
    "                    elif gdf1.loc[gdf1_index, set1_geometry_col].contains(end_pt):\n",
    "                        interact_str = ['End']\n",
    "                    else:\n",
    "                        interact_str = ['Intersect']\n",
    "\n",
    "                    results.loc[df_index] = np.concatenate((gdf1.loc[gdf1_index, set1_key_cols].values,\n",
    "                                            gdf2.loc[gdf2_index, set2_key_cols].values,\n",
    "                                            interact_str),axis=None)\n",
    "                    df_index += 1\n",
    "            elif gdf1_type == 'LineString' and gdf2_type == 'LineString':\n",
    "                interaction = gdf1.loc[gdf1_index, set1_geometry_col].intersects(gdf2.loc[gdf2_index, set2_geometry_col])\n",
    "                if interaction:\n",
    "                    interact_str = ['Intersect']\n",
    "\n",
    "                    results.loc[df_index] = np.concatenate((gdf1.loc[gdf1_index, set1_key_cols].values,\n",
    "                                            gdf2.loc[gdf2_index, set2_key_cols].values,\n",
    "                                            interact_str),axis=None)\n",
    "                    df_index += 1\n",
    "            elif gdf1_type == 'Polygon' and gdf2_type == 'Polygon':\n",
    "                interaction = gdf1.loc[gdf1_index, set1_geometry_col].intersects(gdf2.loc[gdf2_index, set2_geometry_col])\n",
    "                if interaction:\n",
    "                    if gdf1.loc[gdf1_index, set1_geometry_col].contains(gdf2.loc[gdf2_index, set2_geometry_col]):\n",
    "                        interact_str = ['Contains']\n",
    "                    else:\n",
    "                        interact_str = ['Intersect']\n",
    "\n",
    "                    results.loc[df_index] = np.concatenate((gdf1.loc[gdf1_index, set1_key_cols].values,\n",
    "                                            gdf2.loc[gdf2_index, set2_key_cols].values,\n",
    "                                            interact_str),axis=None)\n",
    "                    df_index += 1\n",
    "            elif gdf1_type == 'Polygon' and gdf2_type == 'Point':            \n",
    "                if gdf2.loc[gdf2_index, set2_geometry_col].within(gdf1.loc[gdf1_index, set1_geometry_col]):\n",
    "                    results.loc[df_index] = np.concatenate((gdf1.loc[gdf1_index, set1_key_cols].values,\n",
    "                                                            gdf2.loc[gdf2_index, set2_key_cols].values,\n",
    "                                                            \"Contained\"),axis=None)\n",
    "                    df_index += 1\n",
    "\n",
    "            else:\n",
    "                print('no match')\n",
    "                \n",
    "                \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b50adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read FIR Codes\n",
    "df = pd.read_csv('data/NA_FIR_Codes.csv')\n",
    "\n",
    "# Read Vertices\n",
    "df2 = pd.read_csv('data/vertices_20220621.csv')\n",
    "\n",
    "# Read Spaceports\n",
    "df3 = pd.read_csv ('data/spaceports_20201027.csv')\n",
    "\n",
    "# Read pickle file with topics and augmented text\n",
    "#df4 = pd.read_pickle(\"data/allData.pkl\")\n",
    "\n",
    "# Read Polygon File\n",
    "df5 = pd.read_csv('data/polygon_20201027.csv')\n",
    "\n",
    "# Read Basemap Shapefile\n",
    "states = geopandas.read_file('data/bound_p.shx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f3b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saebasan\\anaconda3\\envs\\spatial\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "#Convert the latitude/longtitude values to geospatial points\n",
    "spaceport_df = df3\n",
    "\n",
    "spaceport_df['FacilityLocation'] = [geometry.Point(xy) for xy in zip(spaceport_df['LONGITUDE'], spaceport_df['LATITUDE'])]\n",
    "\n",
    "\n",
    "spaceport_df['radius'] = 100\n",
    "spaceport_df['units'] = 'nm'\n",
    "\n",
    "spaceport_df = spaceport_df[spaceport_df['SPACEPORT_REC_ID'] > 1]\n",
    "\n",
    "sp_df_2 = gen_geocircle(spaceport_df, 'SPACEPORT_REC_ID', 'FacilityLocation', 'radius', 'units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3678a518-445c-4239-9064-e62c1b6212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IDs for Candidate NOTAMs\n",
    "#id_list = getIds(filterE, df5)\n",
    "\n",
    "#id_list = [39421, 52823, 60100, 77638]\n",
    "id_list = [13425, 13426, 13427, 13428, 13434, 16347, 17108, 17109, 17110, 17115, 17117, 17118, 17119]\n",
    "\n",
    "#id_list = [21892, 21894, 21896, 21898, 21906, 21908, 21912, 21913, 21916, 21917, 21927, 21928, 21929, 21931, 21933, 21935, 21937, 21942, 21943, 21945, 21946, 21957, 21958, 21960, 21962, 21966, 21967, 22081, 22082, 22089, 23055, 23060, 23067, 23068, 23071]\n",
    "\n",
    "# Get Polygons for Candidate NOTAMs\n",
    "P = getPolygons(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7208a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.DataFrame(P, index=['boundary']).rename_axis('polygon_id', axis=1).transpose().reset_index()\n",
    "\n",
    "sp_df_2.reset_index(inplace=True)\n",
    "\n",
    "interactions_df = find_interactions(sp_df_2, test2,\n",
    "                      ['SPACEPORT_REC_ID'], ['polygon_id'],\n",
    "                      'buffer', 'boundary'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c120350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPACEPORT_REC_ID</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>13427</td>\n",
       "      <td>Contained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SPACEPORT_REC_ID polygon_id Interaction\n",
       "0                9      13427   Contained"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278741cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd391c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f221c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81198e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605914a-7759-401d-8f93-6aa9bb9259d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(cmap='Pastel2', figsize=(30, 10))\n",
    "\n",
    "plt.plot(df3['longitude_degrees'], df3['latitude_degrees'], marker=\"o\", markeredgecolor=\"blue\", markerfacecolor=\"black\", markersize=.07, linestyle=\"None\")\n",
    "\n",
    "for item in P:\n",
    "    x,y = item.exterior.xy\n",
    "    plt.plot(x,y, linestyle=\"dashdot\")\n",
    "\n",
    "plt.plot(df2['LONGITUDE'], df2['LATITUDE'], marker=\"o\", markeredgecolor=\"red\", markerfacecolor=\"yellow\", linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3661158-762e-4e7e-af58-d3a7d4400c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = geopandas.read_file('data/bound_p.shx')\n",
    "\n",
    "#df = pd.read_csv ('data/faa_artcc_polygons.csv')\n",
    "df2 = pd.read_csv ('data/spaceports.csv')\n",
    "#df3 = pd.read_csv ('data/AirportData_Clean_20210629_Geocoded.csv')\n",
    "\n",
    "#P = [shapely.wkt.loads(h) for h in df['boundary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a21b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [h for h in sp_df_2['buffer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(cmap='Pastel2', figsize=(30, 10))\n",
    "\n",
    "plt.plot(df3['longitude_degrees'], df3['latitude_degrees'], marker=\"o\", markeredgecolor=\"blue\", markerfacecolor=\"black\", markersize=.07, linestyle=\"None\")\n",
    "\n",
    "for item in P:\n",
    "    x,y = item.exterior.xy\n",
    "    plt.plot(x,y, linestyle=\"dashdot\")\n",
    "\n",
    "plt.plot(df2['LONGITUDE'], df2['LATITUDE'], marker=\"o\", markeredgecolor=\"red\", markerfacecolor=\"yellow\", linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b14c9d",
   "metadata": {},
   "source": [
    "# Dynamic plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92878e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd37b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Base Map\n",
    "states.plot(cmap='Pastel2', figsize=(30, 10))\n",
    "\n",
    "# Plot NOTAM Polygons\n",
    "for item in P.values():\n",
    "    #if P:\n",
    "     #   continue\n",
    "    if item.geom_type != 'Polygon':\n",
    "        plt.plot(*item.xy)\n",
    "    else:\n",
    "        x,y = item.exterior.xy\n",
    "        plt.plot(x,y)\n",
    "\n",
    "# Plot Spaceport Locations\n",
    "#plt.plot(df3['LONGITUDE'], df3['LATITUDE'], marker=\"o\", markeredgecolor=\"red\", markerfacecolor=\"yellow\", linestyle=\"None\")\n",
    "\n",
    "# Set Zoom\n",
    "#plt.axis([-83, -78, 38, 45])\n",
    "plt.axis([-162, -60, 10, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffa905",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84629e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.DataFrame.from_dict(P, orient='index', columns = ['boundary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9147c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.columns = ['Polygon_ID','boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf55daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
